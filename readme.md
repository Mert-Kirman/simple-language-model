# Simple Probabilistic Language Model

This project implements a simple probabilistic language model using conditional probabilities calculated from a dataset of sentences. The model can generate sentences, compute their probabilities, and compare the likelihood of different sentences. It uses a basic mechanism similar to how large language models (LLMs) operate, but on a much smaller scale.

---

## Overview

### Goal
The primary goal of this project is to:
1. Build a language model that learns conditional probabilities from a dataset of sentences.
2. Generate sentences based on conditional probabilities.
3. Calculate the probability (or log-probability) of a given sentence.

### How It Works
1. **Training Phase**:
   - The model reads sentences from a text file (`sentences.txt`) and calculates:
     - **Word Counts**: The frequency of each word in the dataset.
     - **Word Pair Counts**: The frequency of each pair of consecutive words in the dataset.
   - These counts are used to compute the **conditional probability** of one word following another:
     
     P(word2 | word1) = Count(word1, word2) / Count(word1)
     

2. **Sentence Generation**:
   - Sentences are generated by starting with a special token `<|start|>` and repeatedly sampling the next word based on the conditional probability distribution until the `<|end|>` token is reached.

3. **Sentence Probability**:
   - The probability of a sentence is computed as the product of the conditional probabilities of its consecutive word pairs.
     
   - To avoid numerical underflow, the **logarithmic probability** of a sentence is calculated.
     

---

## Features

### **1. Conditional Probability Calculation**
- The model calculates conditional probabilities P(word2 | word1)  based on word pair frequencies in the training data.

### **2. Sentence Generation**
- Sentences are generated probabilistically by sampling from the conditional probability distribution of the next word given the current word.

### **3. Logarithmic Sentence Probability**
- The log-probability of a given sentence is computed to measure how likely the sentence is under the trained model.

### **4. Compare Sentence Probabilities**
- The model can compute and compare the probabilities of two or more sentences.

---

## Implementation

### Code Structure
1. **`cond_probability(word1, word2)`**:
   - Computes the conditional probability P(word2 | word1).

2. **`generate_sentence()`**:
   - Generates a sentence starting with `<|start|>` and ending with `<|end|>` based on conditional probabilities.

3. **`sentence_log_probability(sentence)`**:
   - Computes the logarithmic probability of a given sentence.

4. **Main Execution**:
   - Reads the dataset (`sentences.txt`) to calculate word and word-pair counts.
   - Generates sentences and computes their probabilities.

---

## Usage

### Requirements
- Python 3.x
- Libraries: `numpy`

### Running the Code
1. Place your training data (`sentences.txt`) in the same directory as the script. The file should contain one sentence per line.
2. Run the script to perform the following tasks:
   - Generate new sentences based on the language model.
   - Compute and compare the probabilities of specific sentences.

```bash
python main.py
